---
title: "Training / Test Sets"
author: "Niamh Harford 20251644"
date: "6/8/2021"
output: html_document
---

```{r}
# Load in 2011/2012 data
load("Data/data1_11a.RData")

# Load in 2015/2016 Data
load("Data/hyp1.RData")
```


```{r}
# Load in necessary packages
suppressMessages(library(tidyverse))
suppressMessages(library(sjPlot))
suppressMessages(library(sjlabelled))
suppressMessages(library(sjmisc))
suppressMessages(library(randomForest))
suppressMessages(library(nnet))
```


**Things to note **

+ 2011/2012 Data set will be my training and validation set

+ 2015/2016 Data set will be my test set

+ Training set where I am fitting the model 

+ Validation set where I am comparing results of the fit 

+ Test set is used to evaluate a model fit in the form of the test error rate


**Setting up the data **

```{r}
# Training Data

Train <- data_11a
  
#Test Data

Test <- hyp1
```



**Random Forest**

```{r}
set.seed(1)

f1 <- randomForest(Hypertension ~ .,Train, importance=T)

# Training error
preda <- predict(f1, Train)
mean(preda != Train$Hypertension)*100 # training error
# Test error
predb <- predict(f1, Test)
mean(predb != Test$Hypertension)*100

f1


# suppressMessages(library(condvis2))
# fit1args <- list(ptrans=exp)
# condvis(Train, f3, sectionvars="Hypertension",
# predictArgs=list(fit1args))
```


**Neural Network**

```{r}
set.seed(123)

f2 <- nnet(Hypertension ~ ., data=Train, size=6)
f2

# NN
# Training Data

tab1 <- table(predict(f2, Train, type="class"), Train$Hypertension)
tab1
```


```{r}
# NN training Error rate
(tab1[1]+tab1[4]) / sum(tab1) *100 # around 25-27%


# Specificity 
specificity <- (tab1[2,1]) / (tab1[2,1]+tab1[2,2])
specificity *100 # ~65%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab1[1,2]) / (tab1[1,1]+tab1[1,2])
sensitivity *100 # ~78%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab1[1,2])/(tab1[1,2]+tab1[2,2])
precision *100 # ~81%


# Test Data

tab1 <- table(predict(f2, Test,type="class"), Test$Hypertension)
tab1


# NN test Error rate
(tab1[1]+tab1[4]) / sum(tab1) *100 # around 26-27%


# Specificity 
specificity <- (tab1[2,1])/ (tab1[2,1]+tab1[2,2])
specificity *100 # 61%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab1[1,2]) / (tab1[1,1]+tab1[1,2])
sensitivity *100 # 80%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab1[1,2])/(tab1[1,2]+tab1[2,2])
precision *100 #78%

# Accuracy
accuracy <- (tab1[2,1]+tab1[1,2])/sum(tab1)
accuracy *100
```


**Logistic Regression 1**

```{r}
Train$Hypertension <-ifelse(Train$Hypertension == "Yes", 1 ,0)

f3 <- glm(Hypertension~.,family="binomial",
          data=Train)
pred1 <- predict(f3, Test, type="response")
pred1 <- factor(ifelse(pred1 < .5, "No", "Yes"))
tab1 <- table(Test$Hypertension, pred1)
tab1

# Logistic Regression 1 Error rate
(tab1[1]+tab1[4]) / sum(tab1) *100 # around 26-27%


# Specificity 
specificity <- (tab1[2,1])/ (tab1[2,1]+tab1[2,2])
specificity *100 # 81%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab1[1,2]) / (tab1[1,1]+tab1[1,2])
sensitivity *100 # 58%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab1[1,2])/(tab1[1,2]+tab1[2,2])
precision *100 #63%
```


**Logistic Regression 2 - with gender interaction**

```{r}
f4 <- glm(Hypertension~.*Gender,family="binomial",
          data=Train)
pred2 <- predict(f4, Test, type="response")
pred2 <- factor(ifelse(pred2 < .5, "No", "Yes"))
tab1 <- table(Test$Hypertension, pred2)
tab1

# Logistic Regression 2 Error rate
(tab1[1]+tab1[4]) / sum(tab1) *100 # around 26-27%


# Specificity 
specificity <- (tab1[2,1])/ (tab1[2,1]+tab1[2,2])
specificity *100 # 81%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab1[1,2]) / (tab1[1,1]+tab1[1,2])
sensitivity *100 # 58%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab1[1,2])/(tab1[1,2]+tab1[2,2])
precision *100 #63%
```

**GAM**

```{r}
suppressMessages(library(gam))
gam_logistic = gam(Hypertension ~ Gender + bs(Age, df = 5) + Race + Smoking + Diabetes + 
                     Insulin + KidneyF + BMI + PhysActivity + Alcohol + Salt +
                     Potassium, data=data_11a, family = binomial())
```



**ROC** in the class(5 and 5.3) lecture

```{r}
#ROC RandomForest
require(pROC)
suppressMessages(library(ROCR))
load("Data/data1_11a.RData")
Train <- data_11a

prob <- predict(f1, type = "prob")[,2]
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value



#ROC NN
prob <- predict(f2,  Train)
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Neural Network",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value


#ROC Logistic Regression 1
prob <- predict(f3,  Train)
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Logistic Regression 1",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value

#ROC Logistic Regression 2
prob <- predict(f4,  Train)
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Logistic Regression 2",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value
```



