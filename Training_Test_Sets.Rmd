---
title: "Training / Test Sets"
author: "Niamh Harford 20251644"
date: "6/8/2021"
output: html_document
---

```{r}
# Load in 2011/2012 data
load("Data/data1_11a.RData")

# Load in 2015/2016 Data
load("Data/hyp1.RData")
```


```{r}
# Load in necessary packages
suppressMessages(library(tidyverse))
suppressMessages(library(sjPlot))
suppressMessages(library(sjlabelled))
suppressMessages(library(sjmisc))
suppressMessages(library(randomForest))
suppressMessages(library(nnet)) 
suppressMessages(library(DALEX))
```


**Things to note **

+ 2011/2012 Data set will be my training and validation set

+ 2015/2016 Data set will be my test set

+ Training set where I am fitting the model 

+ Validation set where I am comparing results of the fit 

+ Test set is used to evaluate a model fit in the form of the test error rate


**Setting up the data **

```{r}
# Training Data

Train <- data_11a
  
#Test Data

Test <- hyp1
```



```{r}
set.seed(123)


Train$Hypertension <- factor(ifelse(Train$Hypertension == "Yes", 1 ,0))
Test$Hypertension <- factor(ifelse(Test$Hypertension == "Yes", 1 ,0))


f1 <-glm(Hypertension ~ (Age+I(Age^2) + BMI+I(BMI^2))*Gender+Race + Smoking + Diabetes + 
            KidneyF + PhysActivity + Alcohol + Salt +
            Potassium, data=Train, family = binomial())
 

f2 <- randomForest(Hypertension ~ .,Train, importance = T)


f3 <- nnet(Hypertension ~ ., Train, size = 6)

hypn <- as.numeric(Train$Hypertension)-1
ex_log <- DALEX::explain(f1, data = Train, y = hypn)
ex_rf <- DALEX::explain(f2, data = Train, y = hypn)
ex_nn <-  DALEX::explain(f3, data = Train, y = hypn)

 


# look at model_performance and plot model_performance for nice way of getting roc and model summaries.

 

model_performance(ex_rf)
model_performance(ex_log)
model_performance(ex_nn)
plot(model_performance(ex_rf),model_performance(ex_log), model_performance(ex_nn), geom = "roc") 
```

```{r}
# Test Errors

# Logistic Regression

pred1 <- predict(f1, Test, type="response")
pred1 <- factor(ifelse(pred1 < .5, 0,1))
tab1 <- table(Test$Hypertension, pred1)
tab1

# Logistic Regression  Error rate
(tab1[1]+tab1[4]) / sum(tab1) *100 # around 26-27%
mean(pred1 != Test$Hypertension)*100 # test error


# Random Forest

# Training error
preda <- predict(f2, Train, type = "class")
mean(preda != Train$Hypertension)*100 # training error

# Test error
predb <- predict(f2, Test, type = "class")
mean(predb != Test$Hypertension)*100



# Neural Network 

# Training Data

pred <- factor(ifelse(predict(f3, Train, type = c("raw","class")) > 0.5,1,0))
tab2 <- table(pred, Train$Hypertension)
tab2



# Neural Network training Error rate
(tab2[1]+tab2[4]) / sum(tab2) *100 # around 25-27%



# Test Data

pred1 <- factor(ifelse(predict(f3, Test, type =c("raw","class")) > 0.5,1,0))
tab3 <- table(pred1, Test$Hypertension)
tab3
# Neural Network test Error rate
(tab3[2]+tab3[3]) / sum(tab3) *100 # ~25-27%



# CVpredict(f3)
```


```{r,eval=FALSE}
# STATS

# Logistic 
# Specificity 
specificity <- (tab1[2,1])/ (tab1[2,1]+tab1[2,2])
specificity *100 # 81%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab1[1,2]) / (tab1[1,1]+tab1[1,2])
sensitivity *100 # 58%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab1[1,2])/(tab1[1,2]+tab1[2,2])
precision *100 #63%







# Neural Network Training
# Specificity 
specificity <- (tab2[2,1]) / (tab2[2,1]+tab2[2,2])
specificity *100 # ~65%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab2[1,2]) / (tab2[1,1]+tab2[1,2])
sensitivity *100 # ~78%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab2[1,2])/(tab2[1,2]+tab2[2,2])
precision *100 # ~81%




# Neural Network Test
# Specificity
specificity <- tab3[2,1]/(tab3[2,1]+tab3[2,2])
specificity *100 # ~61%

# Type 1 error
type1_error <- 1 - specificity
type1_error

#Sensitivity
sensitivity <- (tab3[1,2]) / (tab3[1,1]+tab3[1,2])
sensitivity *100 # ~80%

# Type 1 error
type2_error <- 1 - sensitivity
type2_error

# Precision
precision <- (tab3[1,2])/(tab3[1,2]+ tab3[2,2])
precision *100 # ~78%

# Accuracy
accuracy <- (tab3[2,1]+tab3[1,2])/sum(tab3)
accuracy *100



```



```{r}
suppressMessages(library(ROCR))

#ROC RF
prob <- predict(f2, type = "prob")[,2]
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value



#ROC NN
prob <- predict(f3,  Train)
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Neural Network",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value


#ROC Logistic Regression
prob <- predict(f1,  Train)
pred <- prediction(prob, Train$Hypertension)
perf <- performance(pred,"tpr","fpr")
plot(perf,main="ROC Curve for Logistic Regression 1",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc <- performance(pred,"auc")
str(auc) #AUC value
```


```{r}
citation(package = "sjPlot")
citation(package = "DALEX")
citation(package = "nhanesA")
citation(package = "condvis2")
```




