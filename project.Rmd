---
title: "Dissertation"
author: "Niamh Harford 20251644"
date: "3/4/2021"
output: html_document
---

This week:

I removed three variables due to a large amount of NA values : SMQ040 (smoking), PAD675 (physical activity) and ALQ120Q (alcohol use)

I added two new variables in replace of PAQ665 (physical activity) and ALQ101 (alcohol use):

• PAQ665 which is:	In a typical week {do you/does SP} do any moderate-intensity sports, fitness, or recreational activities that cause a small increase in breathing or heart rate such as brisk walking, bicycling, swimming, or volleyball for at least 10 minutes continuously?
• ALQ101 which is : In any one year, {have you/has SP} had at least 12 drinks of any type of alcoholic beverage? By a drink, I mean a 12 oz. beer, a 5 oz. glass of wine, or a one and a half ounces of liquor.

I used 'naniar' package to visualise the missing values in my full data set and the data set where I have removed the don't know response

I renamed all my variables to give meaningful names.

Created plots for every variable against the response, I used the variable Gender to look for any differences between genders - Look at physical activity and alcohol variables

In the paper they used 'Artificial Neural Networks'. A single perceptron (or neuron) can be imagined as a Logistic Regression. Artificial Neural Network, or ANN, is a group of multiple perceptrons/ neurons at each layer.



```{r}
#Packages I need
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
```


```{r}
#Merging the data 
select_cols <- c('BPQ020','RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'SMQ020', 'DIQ010', 'DIQ050', 'KIQ022', 'BMXBMI', 'PAQ665','ALQ101', 'DBD100', 'DR1TPOTA')
all_dat <- Reduce(merge, list(demo_i, smq_i, diq_i, kiq_u_i, bmx_i, bpq_i, paq_i, alq_i,dr1tot_i))
all_dat <- all_dat %>% select(all_of(select_cols))
head(all_dat)
```


```{r}
#Adjust the structure of the data
glimpse(all_dat)
all_dat$RIDAGEYR <- as.numeric(all_dat$RIDAGEYR)
all_dat$BMXBMI <- as.numeric(all_dat$BMXBMI)
all_dat$PAQ665 <- as.numeric(all_dat$PAQ665)
all_dat$ALQ101 <- as.numeric(all_dat$ALQ101)
all_dat$DR1TPOTA <- as.numeric(all_dat$DR1TPOTA)
glimpse(all_dat)
```

```{r}
#Save the file locally
save(all_dat, file = "all_dat.RData")
load("all_dat.RData")
```

```{r}
#checking the responses for each factor variables
levels(all_dat$RIDRETH1) #dont need to fix anything
levels(all_dat$SMQ020) #need to remove dont knows
levels(all_dat$SMQ040) #dont need to fix anything
levels(all_dat$DIQ010) #need to remove dont knows
levels(all_dat$DIQ050) #need to remove dont knows
levels(all_dat$KIQ022) #need to remove dont knows
levels(all_dat$DBD100) #need to remove dont knows
```

```{r}
#removing the unknown "dont know" answers from the data

hyp <- all_dat %>% filter(BPQ020 != "Don't know") %>% filter(SMQ020 != "Don't know") %>% 
    filter(DIQ010 != "Don't know") %>% filter(DIQ050 != "Don't know") %>% 
        filter(KIQ022 != "Don't know") %>% filter(DBD100 != "Don't know")
```

```{r}
#readjusting the levels for each factor variable
hyp <- hyp %>% droplevels()
```

```{r}
#checking the levels are adjusted correctly
levels(hyp$DIQ010)
levels(hyp$SMQ020)
levels(hyp$DIQ010)
levels(hyp$DIQ050)
levels(hyp$KIQ022)
levels(hyp$DBD100)

head(hyp)
table(hyp$BPQ020)
```

```{r}
#Save the file locally
#save(hyp, file = "hyp.RData")
load("hyp.RData")
```

```{r}
glimpse(hyp)
```


```{r}
#Count how much Na values in each variable

hyp %>%
  summarise(count_hyp = sum(is.na(BPQ020)),
            count_gender = sum(is.na(RIAGENDR)),
            count_age = sum(is.na(RIDAGEYR)),
            count_race = sum(is.na(RIDRETH1)),
            count_smoke20 = sum(is.na(SMQ020)),
            count_diabetes10 = sum(is.na(DIQ010)),
            count_diabetes50 = sum(is.na(DIQ050)),
            count_kidney = sum(is.na(KIQ022)),
            count_age = sum(is.na(RIDAGEYR)),
            count_bmi = sum(is.na(BMXBMI)),
            count_activity = sum(is.na(PAQ665)),
            count_alcohol = sum(is.na(ALQ101)),
            count_salt = sum(is.na(DBD100)),
            count_potassium = sum(is.na(DR1TPOTA)))
```


```{r}
#Visualise the number of missing values

library(naniar)
gg_miss_var(all_dat) + theme_bw() #All data
gg_miss_var(hyp) + theme_bw() #Data with dont know responses removed

#DBD100 now has 0 missing values after removing dont know responses
```


```{r}
nrow(hyp)
#3458
hyp1 <- na.omit(hyp)
nrow(hyp1)
#3267
```



```{r}
#I am going to try this code for the all_dat dataset (no levels have been altered)
nrow(all_dat)
#5464
all_dat1 <- na.omit(all_dat)
nrow(all_dat1)
#3289
```

There seems to be no major difference between the two datasets (hyp, with levels altered and all_dat) when I omit the NA values

```{r}
#Rename the variables to meaningful names
hyp2 <- hyp1 %>% rename(Hypertension = BPQ020,
                        Gender = RIAGENDR,
                        Age = RIDAGEYR,
                        Race = RIDRETH1,
                        Smoking = SMQ020,
                        Diabetes = DIQ010,
                        Insulin = DIQ050,
                        KidneyF = KIQ022,
                        BMI = BMXBMI,
                        PhysActivity = PAQ665,
                        Alcohol = ALQ101,
                        Salt = DBD100,
                        Potassium = DR1TPOTA
                        )
```


```{r}
save(hyp2, file = "hyp2.RData")
load("hyp2.RData")
glimpse(hyp2)
```




```{r}
#Logistic regression

log_reg <- glm(Hypertension ~ ., data = hyp2, family = binomial())
summary(log_reg)

```








